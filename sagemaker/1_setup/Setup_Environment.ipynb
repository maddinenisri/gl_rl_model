{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Environment Setup\n",
    "\n",
    "Single consolidated notebook for setting up the GL RL Model environment on SageMaker.\n",
    "\n",
    "**Instance Type**: ml.t2.medium (CPU) or any SageMaker instance\n",
    "**Kernel**: Python 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Quick Setup (Run Shell Script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the consolidated setup script\n",
    "!bash ../../sagemaker/1_setup/setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Manual Setup (Step by Step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install compiled packages with conda (avoids CMake build issues)\n",
    "%conda install -c conda-forge sentencepiece pyarrow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Install PyTorch\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Install ML libraries\n",
    "%pip install transformers datasets peft trl accelerate huggingface-hub tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Install utilities and fix dependencies\n",
    "%pip install --upgrade numpy pandas protobuf tqdm fsspec aiohttp multiprocess>=0.70.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import platform\n",
    "\n",
    "print(\"System Information:\")\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Machine: {platform.machine()}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test all imports\n",
    "packages = {\n",
    "    \"torch\": \"PyTorch\",\n",
    "    \"transformers\": \"Transformers\",\n",
    "    \"datasets\": \"Datasets\",\n",
    "    \"peft\": \"PEFT\",\n",
    "    \"trl\": \"TRL\",\n",
    "    \"sentencepiece\": \"Sentencepiece\",\n",
    "    \"pyarrow\": \"PyArrow\",\n",
    "    \"accelerate\": \"Accelerate\"\n",
    "}\n",
    "\n",
    "all_good = True\n",
    "for module_name, display_name in packages.items():\n",
    "    try:\n",
    "        module = __import__(module_name)\n",
    "        version = getattr(module, \"__version__\", \"unknown\")\n",
    "        print(f\"‚úÖ {display_name}: {version}\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {display_name}: Not installed\")\n",
    "        all_good = False\n",
    "\n",
    "# Check CUDA\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"Device: CPU (Expected on ml.t2.medium)\")\n",
    "    print(\"For GPU training, use sagemaker/2_training/GPU_Training.ipynb\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "if all_good:\n",
    "    print(\"‚úÖ All packages installed successfully!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Some packages need to be installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Test Qwen model tokenizer\n",
    "model_name = \"Qwen/Qwen2.5-Coder-1.5B-Instruct\"\n",
    "print(f\"Loading {model_name} tokenizer...\")\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    \n",
    "    # Test tokenization\n",
    "    test_text = \"SELECT * FROM users WHERE age > 25;\"\n",
    "    tokens = tokenizer.encode(test_text)\n",
    "    decoded = tokenizer.decode(tokens)\n",
    "    \n",
    "    print(\"‚úÖ Tokenizer loaded successfully!\")\n",
    "    print(f\"\\nTest: '{test_text}'\")\n",
    "    print(f\"Tokens: {len(tokens)}\")\n",
    "    print(f\"Decoded: '{decoded}'\")\n",
    "    print(f\"\\nVocabulary size: {tokenizer.vocab_size}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error: {e}\")\n",
    "    print(\"This might be a network issue. Retry or check internet connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Create training data directory\n",
    "os.makedirs(\"data/training\", exist_ok=True)\n",
    "\n",
    "# Sample training data\n",
    "sample_data = [\n",
    "    {\"query\": \"Show me all customers\", \"sql\": \"SELECT * FROM customers;\", \"context\": \"customers(id, name, email, created_at)\"},\n",
    "    {\"query\": \"Get total sales by month\", \"sql\": \"SELECT DATE_FORMAT(date, '%Y-%m') as month, SUM(amount) as total FROM sales GROUP BY month;\", \"context\": \"sales(id, date, amount, product_id)\"},\n",
    "    {\"query\": \"Find top 5 products by revenue\", \"sql\": \"SELECT p.name, SUM(s.amount) as revenue FROM products p JOIN sales s ON p.id = s.product_id GROUP BY p.id ORDER BY revenue DESC LIMIT 5;\", \"context\": \"products(id, name, price), sales(id, product_id, amount)\"},\n",
    "    {\"query\": \"List users who registered today\", \"sql\": \"SELECT * FROM users WHERE DATE(created_at) = CURDATE();\", \"context\": \"users(id, name, email, created_at)\"},\n",
    "    {\"query\": \"Calculate average order value\", \"sql\": \"SELECT AVG(total_amount) as avg_order_value FROM orders;\", \"context\": \"orders(id, customer_id, total_amount, order_date)\"}\n",
    "]\n",
    "\n",
    "# Write to file\n",
    "data_file = \"data/training/query_pairs.jsonl\"\n",
    "with open(data_file, 'w') as f:\n",
    "    for item in sample_data:\n",
    "        f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "print(f\"‚úÖ Created training data: {data_file}\")\n",
    "print(f\"Number of examples: {len(sample_data)}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample data:\")\n",
    "for i, item in enumerate(sample_data[:2], 1):\n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"  Query: {item['query']}\")\n",
    "    print(f\"  SQL: {item['sql']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Setup Complete!\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **For GPU Training**: Open `sagemaker/2_training/GPU_Training.ipynb`\n",
    "2. **For CPU Inference**: Open `sagemaker/3_inference/CPU_Inference.ipynb`\n",
    "\n",
    "### Key Points:\n",
    "- ‚úÖ All dependencies installed (conda + pip approach)\n",
    "- ‚úÖ No CMake build issues (using precompiled binaries)\n",
    "- ‚úÖ Ready for model training and inference\n",
    "- üí° Remember to stop the instance when not in use!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Training on SageMaker\n",
    "\n",
    "This notebook shows how to launch GPU training jobs on SageMaker.\n",
    "\n",
    "**Two Options:**\n",
    "1. **Training Jobs** (Recommended) - Launch separate GPU instance, auto-shutdown\n",
    "2. **Switch Instance** - Change notebook to GPU (expensive, charges while idle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Initialize SageMaker session\n",
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = session.boto_region_name\n",
    "account_id = session.account_id()\n",
    "bucket = f\"gl-rl-model-sagemaker-{account_id}-{region}\"\n",
    "\n",
    "print(f\"üé≠ Role: {role}\")\n",
    "print(f\"üìç Region: {region}\")\n",
    "print(f\"üì¶ S3 Bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Launch Training Job (Recommended)\n",
    "\n",
    "‚úÖ **Advantages:**\n",
    "- Only pay while training\n",
    "- Automatic shutdown\n",
    "- Spot instances save 70%\n",
    "- Can run multiple jobs in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Training script is already in the scripts directory\n# No need to copy - we'll reference it directly in the estimator"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload training data to S3\n",
    "!aws s3 cp ../../data/training/query_pairs.jsonl s3://{bucket}/data/training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from sagemaker.pytorch import PyTorch\n\n# Configure training job\nestimator = PyTorch(\n    entry_point='train.py',\n    source_dir='../scripts',  # Point to scripts directory\n    role=role,\n    \n    # GPU Instance - Choose one:\n    instance_type='ml.g5.xlarge',     # A10G 24GB VRAM ($0.30/hr spot)\n    # instance_type='ml.g4dn.xlarge',  # T4 16GB VRAM ($0.35/hr spot)\n    # instance_type='ml.p3.2xlarge',   # V100 16GB VRAM ($1.15/hr spot)\n    \n    instance_count=1,\n    \n    # Framework\n    framework_version='2.0',\n    py_version='py310',\n    \n    # Hyperparameters\n    hyperparameters={\n        'model_name': 'Qwen/Qwen2.5-Coder-1.5B-Instruct',\n        'epochs': 3,\n        'batch_size': 4,\n        'learning_rate': 3e-5,\n        'lora_r': 8,\n        'lora_alpha': 16,\n        'gradient_checkpointing': True,\n        'fp16': True,\n    },\n    \n    # Cost Optimization - Use Spot Instances\n    use_spot_instances=True,\n    max_wait=86400,  # 24 hours\n    max_run=86400,   # 24 hours\n    \n    # Output\n    output_path=f's3://{bucket}/output',\n    base_job_name='gl-rl-model-gpu',\n    \n    # Checkpointing for spot interruption recovery\n    checkpoint_s3_uri=f's3://{bucket}/checkpoints',\n    checkpoint_local_path='/opt/ml/checkpoints',\n)\n\nprint(\"‚úÖ Estimator configured\")\nprint(\"üí∞ Cost estimate:\")\nprint(\"  ml.g5.xlarge spot: ~$0.30/hour\")\nprint(\"  Training time: ~2-4 hours\")\nprint(\"  Total cost: ~$0.60-$1.20\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch training job\n",
    "job_name = f\"gl-rl-gpu-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "print(f\"üöÄ Launching job: {job_name}\")\n",
    "\n",
    "estimator.fit(\n",
    "    inputs={'training': f's3://{bucket}/data/training'},\n",
    "    job_name=job_name,\n",
    "    wait=False  # Don't block notebook\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Job submitted!\")\n",
    "print(f\"üìä Monitor: https://console.aws.amazon.com/sagemaker/home?region={region}#/jobs/{job_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_job_status(job_name):\n",
    "    \"\"\"Check training job status\"\"\"\n",
    "    sm = boto3.client('sagemaker', region_name=region)\n",
    "    \n",
    "    try:\n",
    "        job = sm.describe_training_job(TrainingJobName=job_name)\n",
    "        status = job['TrainingJobStatus']\n",
    "        \n",
    "        print(f\"Job: {job_name}\")\n",
    "        print(f\"Status: {status}\")\n",
    "        \n",
    "        if status == 'InProgress':\n",
    "            print(f\"Secondary Status: {job.get('SecondaryStatus', 'Starting')}\")\n",
    "            if 'TrainingStartTime' in job:\n",
    "                elapsed = datetime.now(job['TrainingStartTime'].tzinfo) - job['TrainingStartTime']\n",
    "                print(f\"Elapsed: {elapsed}\")\n",
    "                \n",
    "        elif status == 'Completed':\n",
    "            print(\"‚úÖ Training completed!\")\n",
    "            print(f\"Model: {job['ModelArtifacts']['S3ModelArtifacts']}\")\n",
    "            if 'TrainingStartTime' in job and 'TrainingEndTime' in job:\n",
    "                duration = job['TrainingEndTime'] - job['TrainingStartTime']\n",
    "                print(f\"Duration: {duration}\")\n",
    "                \n",
    "                # Calculate cost\n",
    "                hours = duration.total_seconds() / 3600\n",
    "                spot_price = 0.30  # ml.g5.xlarge spot price\n",
    "                cost = hours * spot_price\n",
    "                print(f\"Estimated cost: ${cost:.2f}\")\n",
    "                \n",
    "        elif status == 'Failed':\n",
    "            print(f\"‚ùå Failed: {job.get('FailureReason', 'Unknown')}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Check your job (replace with actual job name)\n",
    "# check_job_status(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Quick Launch Script\n",
    "\n",
    "For command-line launching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate launch script\n",
    "launch_script = f\"\"\"#!/bin/bash\n",
    "# Quick GPU training launch script\n",
    "\n",
    "JOB_NAME=\"gl-rl-gpu-$(date +%Y%m%d-%H%M%S)\"\n",
    "\n",
    "aws sagemaker create-training-job \\\\\n",
    "  --training-job-name $JOB_NAME \\\\\n",
    "  --role-arn {role} \\\\\n",
    "  --algorithm-specification TrainingImage=763104351884.dkr.ecr.{region}.amazonaws.com/pytorch-training:2.0-gpu-py310,TrainingInputMode=File \\\\\n",
    "  --resource-config InstanceType=ml.g5.xlarge,InstanceCount=1,VolumeSizeInGB=50 \\\\\n",
    "  --input-data-config '[{{\"ChannelName\":\"training\",\"DataSource\":{{\"S3DataSource\":{{\"S3DataType\":\"S3Prefix\",\"S3Uri\":\"s3://{bucket}/data/training\",\"S3DataDistributionType\":\"FullyReplicated\"}}}}}}]' \\\\\n",
    "  --output-data-config S3OutputPath=s3://{bucket}/output \\\\\n",
    "  --enable-managed-spot-training \\\\\n",
    "  --stopping-condition MaxRuntimeInSeconds=86400,MaxWaitTimeInSeconds=86400 \\\\\n",
    "  --region {region}\n",
    "\n",
    "echo \"‚úÖ Launched job: $JOB_NAME\"\n",
    "echo \"üìä Monitor at: https://console.aws.amazon.com/sagemaker/home?region={region}#/jobs/$JOB_NAME\"\n",
    "\"\"\"\n",
    "\n",
    "with open('launch_training.sh', 'w') as f:\n",
    "    f.write(launch_script)\n",
    "\n",
    "print(\"‚úÖ Created launch_training.sh\")\n",
    "print(\"Run with: bash launch_training.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model(job_name):\n",
    "    \"\"\"Download trained model from S3\"\"\"\n",
    "    sm = boto3.client('sagemaker', region_name=region)\n",
    "    \n",
    "    job = sm.describe_training_job(TrainingJobName=job_name)\n",
    "    \n",
    "    if job['TrainingJobStatus'] == 'Completed':\n",
    "        model_uri = job['ModelArtifacts']['S3ModelArtifacts']\n",
    "        print(f\"Downloading model from: {model_uri}\")\n",
    "        \n",
    "        !aws s3 cp {model_uri} ./model.tar.gz\n",
    "        !tar -xzf model.tar.gz\n",
    "        \n",
    "        print(\"‚úÖ Model downloaded and extracted\")\n",
    "        !ls -la\n",
    "    else:\n",
    "        print(f\"Job status: {job['TrainingJobStatus']}\")\n",
    "\n",
    "# download_model(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Optimization Guide\n",
    "\n",
    "### Instance Selection\n",
    "\n",
    "| Instance | GPU | VRAM | On-Demand | Spot | Use Case |\n",
    "|----------|-----|------|-----------|------|----------|\n",
    "| ml.g5.xlarge | A10G | 24GB | $1.00/hr | $0.30/hr | **Best value** |\n",
    "| ml.g4dn.xlarge | T4 | 16GB | $0.73/hr | $0.35/hr | Budget option |\n",
    "| ml.p3.2xlarge | V100 | 16GB | $3.83/hr | $1.15/hr | Fast training |\n",
    "\n",
    "### Tips:\n",
    "1. **Always use spot instances** (70% savings)\n",
    "2. **Use checkpointing** for interruption recovery\n",
    "3. **Optimize batch size** for GPU memory\n",
    "4. **Enable mixed precision** (fp16=True)\n",
    "5. **Use gradient checkpointing** for larger models\n",
    "\n",
    "### Monitor Costs:\n",
    "- [AWS Cost Explorer](https://console.aws.amazon.com/cost-management/)\n",
    "- Set budget alerts in AWS Budgets\n",
    "- Tag resources for cost tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Switch Notebook to GPU\n",
    "\n",
    "‚ö†Ô∏è **Warning**: Charges even when idle!\n",
    "\n",
    "1. Stop this notebook instance\n",
    "2. Update settings ‚Üí Change to ml.g5.xlarge\n",
    "3. Start instance\n",
    "4. Run training directly in notebook\n",
    "5. **Remember to switch back to ml.t2.medium after training!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GL RL Model - SageMaker Setup Notebook\n",
    "\n",
    "This notebook properly installs all dependencies using SageMaker best practices.\n",
    "\n",
    "**Important**: Run this notebook using the `Python 3` kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Upgrade pip to ensure we get prebuilt wheels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade pip to ensure we get prebuilt wheels (need >= 19.0)\n",
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install PyTorch (CPU version for ml.t2.medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch CPU version\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install core packages with prebuilt wheels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install numpy and pandas first (they are dependencies for pyarrow)\n",
    "%pip install numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pyarrow using prebuilt wheel\n",
    "%pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Transformers ecosystem\n",
    "%pip install transformers tokenizers huggingface-hub accelerate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install fine-tuning libraries\n",
    "%pip install peft trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional utilities\n",
    "%pip install sentencepiece protobuf tqdm fsspec aiohttp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify all installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all imports\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import datasets\n",
    "import peft\n",
    "import trl\n",
    "import pyarrow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sentencepiece\n",
    "import tokenizers\n",
    "import accelerate\n",
    "\n",
    "print(\"‚úÖ All packages imported successfully!\\n\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Transformers: {transformers.__version__}\")\n",
    "print(f\"Datasets: {datasets.__version__}\")\n",
    "print(f\"PEFT: {peft.__version__}\")\n",
    "print(f\"TRL: {trl.__version__}\")\n",
    "print(f\"PyArrow: {pyarrow.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Sentencepiece: {sentencepiece.__version__}\")\n",
    "print(f\"Tokenizers: {tokenizers.__version__}\")\n",
    "print(f\"Accelerate: {accelerate.__version__}\")\n",
    "print(f\"\\nDevice: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# Check if we're in SageMaker\n",
    "import os\n",
    "is_sagemaker = os.path.exists('/opt/ml/metadata/resource-metadata.json')\n",
    "print(f\"\\nRunning in SageMaker: {is_sagemaker}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clone the repository and set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Navigate to SageMaker directory\n",
    "sagemaker_dir = \"/home/ec2-user/SageMaker\"\n",
    "if os.path.exists(sagemaker_dir):\n",
    "    os.chdir(sagemaker_dir)\n",
    "    print(f\"Changed to directory: {os.getcwd()}\")\n",
    "\n",
    "# Clone or update the repository\n",
    "repo_dir = \"gl_rl_model\"\n",
    "if os.path.exists(repo_dir):\n",
    "    print(\"Repository already exists, pulling latest changes...\")\n",
    "    os.chdir(repo_dir)\n",
    "    !git pull origin main\n",
    "else:\n",
    "    print(\"Cloning repository...\")\n",
    "    !git clone https://github.com/maddinenisri/gl_rl_model.git\n",
    "    os.chdir(repo_dir)\n",
    "\n",
    "print(f\"\\nCurrent directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data directory and sample data\n",
    "import json\n",
    "\n",
    "os.makedirs(\"data/training\", exist_ok=True)\n",
    "\n",
    "# Sample training data\n",
    "sample_data = [\n",
    "    {\"query\": \"Show me all customers\", \"sql\": \"SELECT * FROM customers;\", \"context\": \"customers(id, name, email, created_at)\"},\n",
    "    {\"query\": \"Get total sales by month\", \"sql\": \"SELECT DATE_FORMAT(date, '%Y-%m') as month, SUM(amount) as total FROM sales GROUP BY month;\", \"context\": \"sales(id, date, amount, product_id)\"},\n",
    "    {\"query\": \"Find top 5 products by revenue\", \"sql\": \"SELECT p.name, SUM(s.amount) as revenue FROM products p JOIN sales s ON p.id = s.product_id GROUP BY p.id ORDER BY revenue DESC LIMIT 5;\", \"context\": \"products(id, name, price), sales(id, product_id, amount)\"},\n",
    "    {\"query\": \"List users who registered today\", \"sql\": \"SELECT * FROM users WHERE DATE(created_at) = CURDATE();\", \"context\": \"users(id, name, email, created_at)\"},\n",
    "    {\"query\": \"Calculate average order value\", \"sql\": \"SELECT AVG(total_amount) as avg_order_value FROM orders;\", \"context\": \"orders(id, customer_id, total_amount, order_date)\"}\n",
    "]\n",
    "\n",
    "# Write sample data\n",
    "data_file = \"data/training/query_pairs.jsonl\"\n",
    "if not os.path.exists(data_file):\n",
    "    with open(data_file, 'w') as f:\n",
    "        for item in sample_data:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "    print(f\"‚úÖ Created sample training data: {data_file}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Training data already exists: {data_file}\")\n",
    "\n",
    "# Load and display the data\n",
    "with open(data_file, 'r') as f:\n",
    "    loaded_data = [json.loads(line) for line in f]\n",
    "\n",
    "print(f\"\\nLoaded {len(loaded_data)} training examples:\")\n",
    "for i, example in enumerate(loaded_data[:2], 1):\n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"  Query: {example['query']}\")\n",
    "    print(f\"  SQL: {example['sql']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test tokenizer and model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-Coder-1.5B-Instruct\"\n",
    "print(f\"Testing tokenizer for {model_name}...\\n\")\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    \n",
    "    # Test tokenization\n",
    "    test_text = \"SELECT * FROM users WHERE age > 25;\"\n",
    "    tokens = tokenizer.encode(test_text)\n",
    "    decoded = tokenizer.decode(tokens)\n",
    "    \n",
    "    print(f\"‚úÖ Tokenizer loaded successfully!\")\n",
    "    print(f\"\\nTest text: '{test_text}'\")\n",
    "    print(f\"Token count: {len(tokens)}\")\n",
    "    print(f\"Decoded: '{decoded}'\")\n",
    "    print(f\"\\nTokenizer vocabulary size: {tokenizer.vocab_size}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error loading tokenizer: {e}\")\n",
    "    print(\"This may be due to network issues. You can retry later.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Environment Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ENVIRONMENT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# System info\n",
    "print(f\"\\nüìä System Information:\")\n",
    "print(f\"  Platform: {platform.platform()}\")\n",
    "print(f\"  Python: {platform.python_version()}\")\n",
    "print(f\"  Processor: {platform.processor() or 'N/A'}\")\n",
    "\n",
    "# SageMaker info\n",
    "if os.path.exists('/opt/ml/metadata/resource-metadata.json'):\n",
    "    try:\n",
    "        with open('/opt/ml/metadata/resource-metadata.json', 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        print(f\"\\nüöÄ SageMaker Instance:\")\n",
    "        print(f\"  Instance Type: {metadata.get('InstanceType', 'Unknown')}\")\n",
    "        print(f\"  Region: {metadata.get('Region', 'Unknown')}\")\n",
    "    except:\n",
    "        print(\"\\nüöÄ SageMaker: Running (details unavailable)\")\n",
    "else:\n",
    "    print(\"\\nüíª Running locally (not in SageMaker)\")\n",
    "\n",
    "# GPU info\n",
    "print(f\"\\nüéÆ GPU Status:\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  CUDA Available: Yes\")\n",
    "    print(f\"  GPU Count: {torch.cuda.device_count()}\")\n",
    "    print(f\"  GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(f\"  CUDA Available: No (CPU only)\")\n",
    "    print(f\"  Note: This is expected on ml.t2.medium instances\")\n",
    "    print(f\"  For GPU training, use SageMaker Training Jobs with ml.g5.xlarge\")\n",
    "\n",
    "print(f\"\\n‚úÖ Setup Status: COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìö Next Steps:\")\n",
    "print(\"1. Open GL_RL_Model_Quick_Start.ipynb for the full training pipeline\")\n",
    "print(\"2. Use this notebook instance for development and testing\")\n",
    "print(\"3. For production training, launch GPU jobs with SageMaker Training\")\n",
    "print(\"\\nüí° Tip: To save costs, remember to stop this notebook instance when not in use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Setup Complete!\n",
    "\n",
    "All dependencies have been installed using SageMaker best practices.\n",
    "\n",
    "### Important Notes:\n",
    "\n",
    "1. **Persistence**: Packages installed in this session will persist in `/home/ec2-user/SageMaker`\n",
    "2. **Kernel**: Always use the `Python 3` kernel for consistency\n",
    "3. **GPU Training**: Use SageMaker Training Jobs with `ml.g5.xlarge` spot instances\n",
    "4. **Cost Optimization**: Stop the notebook instance when not in use\n",
    "\n",
    "### To reinstall packages (if needed):\n",
    "\n",
    "```python\n",
    "%pip install <package_name>\n",
    "```\n",
    "\n",
    "### For conda packages (alternative):\n",
    "\n",
    "```python\n",
    "%conda install -c conda-forge <package_name>\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}